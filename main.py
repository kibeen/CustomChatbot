import os
import streamlit as st
from utils import *
from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate
from langchain.memory import ConversationBufferMemory


MODEL = "deepseek-r1:14b"

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ChatGB")
st.title("ğŸ’¬ ChatGB")
st.write(f"Model: {MODEL}")


def init_prompt():
    # **í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ë„ë¡ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì„¤ì •**
    system_prompt = """
    ë‹¹ì‹ ì€ í•œêµ­ì–´ë¥¼ ì‚¬ìš©í•˜ëŠ” AI ì±—ë´‡ì…ë‹ˆë‹¤.
    ëª¨ë“  ì§ˆë¬¸ì— ëŒ€í•´ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
    ë¬¸ì¥ì´ ìì—°ìŠ¤ëŸ½ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ë°©ì‹ìœ¼ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.
    ëŒ€í™”ì˜ ë¬¸ë§¥ì„ ì´í•´í•˜ê³ , ì•ì„  ëŒ€í™” ë‚´ìš©ê³¼ ì—°ê´€ëœ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
    """

    return PromptTemplate(
        template=system_prompt + "\nëŒ€í™” ë‚´ì—­: {history}\nì‚¬ìš©ì ì§ˆë¬¸: {input}\nAI ì‘ë‹µ:",
        input_variables=["history", "input"]
    )


# Ollama DeepSeek ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì±—ë´‡ ìƒì„±
@st.cache_resource
def create_ollama_chatbot():
    from langchain_community.llms import Ollama
    from langchain.chains import LLMChain
    memory = ConversationBufferMemory(memory_key="history", return_messages=True)
    chatbot = LLMChain(
        llm=Ollama(model=MODEL),
        memory=memory,
        prompt=init_prompt()
    )
    return chatbot

# Ollama DeepSeek ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì±—ë´‡ ìƒì„±
@st.cache_resource
def create_gpt_chatbot():
    from langchain_openai import ChatOpenAI
    from langchain.chains import ConversationChain
    memory = ConversationBufferMemory(memory_key="history", return_messages=True)
    os.environ["OPENAI_API_KEY"] = "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"
    chatbot = ConversationChain(
        llm=ChatOpenAI(model_name=MODEL),
        memory=memory
    )
    return chatbot

# Streamlitì˜ session_stateì— ì±—ë´‡ ì €ì¥ (ì´ˆê¸°í™” ë°©ì§€)
if "chatbot" not in st.session_state:
    with st.spinner("DeepSeek ì±—ë´‡ ì´ˆê¸°í™” ì¤‘ì…ë‹ˆë‹¤..."):
        chatbot = create_gpt_chatbot()
        st.session_state.chatbot = chatbot
    st.write("DeepSeek ì±—ë´‡ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤! ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")

# ëŒ€í™” ê¸°ë¡ ì €ì¥
if "messages" not in st.session_state:
    st.session_state.messages = []

# ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
for conversation in st.session_state.messages:
    with st.chat_message(conversation["role"]):
        st.write(conversation["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ ì±—ë´‡ì´ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤."):
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    raw_response = st.session_state.chatbot.run(prompt)  # ì›ë³¸ ì‘ë‹µ ë°›ê¸°
    response = clean_response(raw_response)  # <think> íƒœê·¸ ì œê±° í›„ì²˜ë¦¬
    
    # ì‘ë‹µ ì¶œë ¥
    with st.chat_message("assistant"):
        st.markdown(response)

    # ëŒ€í™” ê¸°ë¡ ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": response})
